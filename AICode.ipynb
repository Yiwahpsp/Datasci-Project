{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "L38NS6rUUHQc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('features_summation_drop_title.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "R9C4Ss_jU7rw",
    "outputId": "58499b2a-43a4-49bd-ad42-06e5411256c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_name</th>\n",
       "      <th>organizations</th>\n",
       "      <th>classifications</th>\n",
       "      <th>affiliations</th>\n",
       "      <th>auth-keywords</th>\n",
       "      <th>reference</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>journal of health research</td>\n",
       "      <td>['College of Public Health Sciences', 'Chulalo...</td>\n",
       "      <td>['ASJC', 'SUBJABBR']</td>\n",
       "      <td>['Chulalongkorn University']</td>\n",
       "      <td>['Antibiotic resistance', 'Antibiotics', 'Nepa...</td>\n",
       "      <td>['What is antimicrobial resistance?', 'PLoS On...</td>\n",
       "      <td>health policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>journal of health research</td>\n",
       "      <td>['Department of Preventive and Social Medicine...</td>\n",
       "      <td>['ASJC', 'SUBJABBR']</td>\n",
       "      <td>['Duke-NUS Medical School', 'Chulalongkorn Uni...</td>\n",
       "      <td>['Adult', 'Dental caries', 'Elderly', 'System ...</td>\n",
       "      <td>['Department of Health, Ministry of Public Hea...</td>\n",
       "      <td>environmental and occupational health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journal of health research</td>\n",
       "      <td>['College of Public Health Sciences', 'Chulalo...</td>\n",
       "      <td>['ASJC', 'SUBJABBR']</td>\n",
       "      <td>['Chulalongkorn University']</td>\n",
       "      <td>['Keywords Contraceptive utilization', 'Myanma...</td>\n",
       "      <td>['Pan Afr Med J', 'Iran J Nurs Midwifery Res',...</td>\n",
       "      <td>public health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>journal of health research</td>\n",
       "      <td>['College of Public Health Sciences', 'Chulalo...</td>\n",
       "      <td>['ASJC', 'SUBJABBR']</td>\n",
       "      <td>['Chulalongkorn University']</td>\n",
       "      <td>['Adolescent health', 'Health belief model', '...</td>\n",
       "      <td>['Sexual and reproductive health of young peop...</td>\n",
       "      <td>health policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>journal of health research</td>\n",
       "      <td>['College of Public Health Sciences', 'Chulalo...</td>\n",
       "      <td>['ASJC', 'SUBJABBR']</td>\n",
       "      <td>['Chulalongkorn University']</td>\n",
       "      <td>['Hepatitis C virus', 'Pakistan', 'Pregnant wo...</td>\n",
       "      <td>['Clin Liver Dis', 'Genomic integration of hep...</td>\n",
       "      <td>public health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 publish_name  \\\n",
       "0  journal of health research   \n",
       "1  journal of health research   \n",
       "2  journal of health research   \n",
       "3  journal of health research   \n",
       "4  journal of health research   \n",
       "\n",
       "                                       organizations       classifications  \\\n",
       "0  ['College of Public Health Sciences', 'Chulalo...  ['ASJC', 'SUBJABBR']   \n",
       "1  ['Department of Preventive and Social Medicine...  ['ASJC', 'SUBJABBR']   \n",
       "2  ['College of Public Health Sciences', 'Chulalo...  ['ASJC', 'SUBJABBR']   \n",
       "3  ['College of Public Health Sciences', 'Chulalo...  ['ASJC', 'SUBJABBR']   \n",
       "4  ['College of Public Health Sciences', 'Chulalo...  ['ASJC', 'SUBJABBR']   \n",
       "\n",
       "                                        affiliations  \\\n",
       "0                       ['Chulalongkorn University']   \n",
       "1  ['Duke-NUS Medical School', 'Chulalongkorn Uni...   \n",
       "2                       ['Chulalongkorn University']   \n",
       "3                       ['Chulalongkorn University']   \n",
       "4                       ['Chulalongkorn University']   \n",
       "\n",
       "                                       auth-keywords  \\\n",
       "0  ['Antibiotic resistance', 'Antibiotics', 'Nepa...   \n",
       "1  ['Adult', 'Dental caries', 'Elderly', 'System ...   \n",
       "2  ['Keywords Contraceptive utilization', 'Myanma...   \n",
       "3  ['Adolescent health', 'Health belief model', '...   \n",
       "4  ['Hepatitis C virus', 'Pakistan', 'Pregnant wo...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  ['What is antimicrobial resistance?', 'PLoS On...   \n",
       "1  ['Department of Health, Ministry of Public Hea...   \n",
       "2  ['Pan Afr Med J', 'Iran J Nurs Midwifery Res',...   \n",
       "3  ['Sexual and reproductive health of young peop...   \n",
       "4  ['Clin Liver Dis', 'Genomic integration of hep...   \n",
       "\n",
       "                                 subject  \n",
       "0                          health policy  \n",
       "1  environmental and occupational health  \n",
       "2                          public health  \n",
       "3                          health policy  \n",
       "4                          public health  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFfAT7gFOoMI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Av_mHtdU1n0X",
    "outputId": "5d953ea5-6a68-40c6-e454-f4d8e79ca321"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 3: Define broad categories (10-15 groups)\n",
    "categories = {\n",
    "\n",
    "   \"Physics and Astronomy\":\n",
    "\n",
    "    {\"physics\", \"astronomy\", \"mathematics\",\"atomic and molecular physics\",\"ecological modeling\",\"numerical analysis\", \"statistics and probability\",\"statistics\" ,\"probability and uncertainty\",\"algebra and number theory\",\n",
    "     \"optical and magnetic materials\",\"geotechnical engineering and engineering geology\",\"history and philosophy of science\",\"applied mathematics\"\n",
    "     \"astrophysics\",\"electronic\",\"safety\", \"risk\",\"reliability and quality\", \"monitoring\",\"signal processing\",\n",
    "     \"space and planetary science\", \"surfaces\",\"physics and astronomy\",\"surfaces and interfaces\",\"applied mathematics\",\n",
    "     \"nuclear physics\", \"high energy physics\", \"statistical and nonlinear physics\", \"mathematical physics\",\"renewable energy\",\"sustainability and the environment\"\n",
    "     ,\"physical and theoretical chemistry\",\"condensed matter physics\",\"energy engineering and power technology\",\"spectroscopy\",\"energy\"},\n",
    "\n",
    "  \"Chemistry\":\n",
    "\n",
    "   {\"chemistry\", \"toxicology and mutagenesis\",\"nuclear and high energy physics\",\"nuclear medicine and imaging\",\"nuclear energy and engineering\",\"geochemistry and petrology\",\n",
    "    \"metals and alloys\",\"atomic and molecular physics\",\"process chemistry and technology\",\"colloid and surface chemistry\",\"geology\",\n",
    "    \"process chemistry and technology\",\"toxicology and pharmaceutics\",\"atomic and molecular physics\",\"and optics\",\"cellular and molecular neuroscience\",\n",
    "    \"analytical chemistry\", \"physical chemistry\", \"organic chemistry\", \"inorganic chemistry\", \"materials chemistry\", \"environmental chemistry\", \"biochemistry\", \"biophysics\",\"catalysis\"},\n",
    "\n",
    "   \"Engineering\":\n",
    "\n",
    "    {\"chemical engineering\",\"instrumentation\", \"building and construction\",\"water science and technology\",\"control and systems engineering\",\"fluid flow and transfer processes\",\"ceramics and composites\",\n",
    "     \"industrial and manufacturing engineering\", \"aerospace engineering\", \"mechanical engineering\", \"civil and structural engineering\",\n",
    "     \"geotechnical engineering\", \"materials science\", \"energy engineering\", \"power engineering\", \"nuclear energy engineering\", \"automotive engineering\", \"acoustics\",\n",
    "     \"human factors and ergonomics\", \"computers in earth sciences\", \"atmospheric science\", \"computational mathematics\", \"geochemistry\", \"petrology\", \"filtration and separation\",\n",
    "     \"geophysics\", \"radiological and ultrasound technology\", \"computational mechanics\", \"electrochemistry\", \"safety research\", \"transportation\", \"architecture\",\"engineering\",\n",
    "     \"polymers and plastics\",         \"environmental engineering\" ,\"fuel technology\",\"mechanics of materials\",\"waste management and disposal\",\"pollution\",\"ecology\",\"toxicology and mutagenesis\"\n",
    "     \"electrical and electronic engineering\",\"ocean engineering\"},\n",
    "\n",
    "  \"Computer Science and Information Technology\":\n",
    "\n",
    "   {\"computer science\", \"software\", \"computer vision and pattern recognition\",\"control and optimization\",\"modeling and simulation\",\n",
    "    \"computer vision\", \"pattern recognition\", \"computer networks\", \"communications\", \"artificial intelligence\",\n",
    "    \"hardware architecture\", \"control systems engineering\", \"electrical engineering\", \"electronics engineering\", \"information systems\", \"data science\",\n",
    "    \"machine learning\", \"computer networks and communications\",\n",
    "    \"electrical and electronic engineering\",\"data mining\", \"cyber security\", \"information security\",\"computer science applications\", \"development\"},\n",
    "\n",
    "   \"Biology\":\n",
    "\n",
    "   {\"biology\", \"otorhinolaryngology\",\n",
    "    \"bioengineering\",\"cancer research\",\"plant science\",\"insect science\",\"urology\",\"nature and landscape conservation\",\"equine\",\"endocrinology\",\"oceanography\",\n",
    "    \"biochemistry\", \"genetics\", \"molecular biology\", \"cell biology\", \"developmental biology\", \"microbiology\", \"immunology\", \"virology\",\n",
    "               \"parasitology\", \"anatomy\", \"physiology\", \"histology\", \"pharmacology\", \"toxicology\", \"neuroscience\", \"neurology\", \"cognitive neuroscience\", \"behavioral neuroscience\",\n",
    "               \"psychiatry\",\"aquatic science\",\"biotechnology\",\"small animals\",\n",
    "     \"psychology\", \"clinical psychology\",\"genetics and molecular biology\" ,\"veterinary\",\"evolution\",\"behavior and systematics\",\"agricultural and biological sciences\"\n",
    "               ,\"environmental science\",\"animal science and zoology\",\"applied microbiology and biotechnology\", \"structural biology\"\n",
    "               },\n",
    "\n",
    "   \"Medicine\":\n",
    "\n",
    "    {\"medicine\", \"medical laboratory technology\",\"health policy\", \"public health\", \"epidemiology\", \"oncology\", \"cardiology\", \"gastroenterology\", \"nephrology\", \"neurology\", \"psychiatry\", \"dermatology\",\n",
    "                \"pediatrics\", \"geriatrics\", \"anesthesiology\", \"surgery\", \"obstetrics and gynecology\", \"ophthalmology\", \"otolaryngology\", \"radiology\", \"pathology\", \"clinical biochemistry\"\n",
    "                , \"hematology\", \"immunology\", \"microbiology\", \"virology\", \"genetics\", \"molecular medicine\", \"pharmaceutical science\", \"drug discovery\", \"biomedical engineering\",\n",
    "                \"biomaterials\", \"regenerative medicine\",\"environmental and occupational health\",\"infectious diseases\"\n",
    "                ,\"multidisciplinary\",\"immunology and allergy\",\"complementary and alternative medicine\",\"oral surgery\",\"perinatology and child health\",\n",
    "     \"health\",\"immunology and microbiology\",\"health informatics\",\"complementary and manual therapy\",\"physical therapy\",\"rehabilitation\"},\n",
    "\n",
    "   \"Agriculture and Food Science\":\n",
    "\n",
    "    {\"agriculture\", \"agronomy\", \"horticulture\", \"nutrition and dietetics \",\"health professions\",\"diabetes and metabolism\",\"agronomy and crop science\",\n",
    "     \"crop science\", \"soil science\", \"nutrition and dietetics\",\"dentistry\",\n",
    "     \"plant science\", \"food science\", \"nutrition\", \"animal science\", \"veterinary medicine\", \"aquaculture\",\"food animals\"},\n",
    " \"Social Sciences\":\n",
    "\n",
    "   {\"sociology\", \"social sciences\",\"psychology\", \"economics\",\"strategy and management\",\"management and accounting\",\"forestry\",\"global and planetary change\",\n",
    "    \"political science\", \"anthropology\", \"history\", \"econometrics and finance\",\"business and international management\",\n",
    "                     \"geography\", \"demography\", \"education\", \"linguistics\", \"philosophy\", \"law\", \"management\", \"business\", \"marketing\",\n",
    "                     \"finance\", \"accounting\", \"economics\", \"operations research\", \"human resource management\", \"organizational behavior\",\n",
    "                     \"information systems\", \"library science\", \"social work\",\"policy and law\",\"economics and econometrics\",\"planning and development\",\"management information systems\",\n",
    "                     \"business and international management\", \"information systems and management\",\"health information management\",\"management science and operations research\",\"tourism\",\"organizational behavior and human resource management\"\n",
    "                     },\n",
    "   \"Humanities\":\n",
    "\n",
    "   {\"history\", \"coatings and films\",\"literature and literary theory\",\"linguistics and language\", \"language and linguistics\",\"visual arts and performing arts\",\n",
    "    \"philosophy\", \"literature\", \"language\", \"art\", \"music\", \"theater\", \"film\", \"religion\", \"cultural studies\",\"paleontology\",\"arts and humanities\",\"religious studies\"}\n",
    "\n",
    "}\n",
    "\n",
    "# Create a mapping from normalized subjects to categories\n",
    "subject_to_category = {}\n",
    "for category, subjects in categories.items():\n",
    "    for subject in subjects:\n",
    "        subject_to_category[subject.lower().strip()] = category  # Normalize key matching\n",
    "\n",
    "# Function to map input subjects using normalization\n",
    "def map_subject_to_category(subject):\n",
    "    # Normalize the input (strip and lower)\n",
    "    normalized_subject = subject.lower().strip()\n",
    "\n",
    "    # Map using cleaned subject_to_category\n",
    "    return subject_to_category.get(normalized_subject, \"Other\")\n",
    "\n",
    "\n",
    "# Map each subject to its corresponding category\n",
    "df[\"grouped_subject\"] = df[\"subject\"].apply(map_subject_to_category)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "IaddgT3xPkn0",
    "outputId": "079210f6-b3c5-47d3-d673-04453e5affa2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_name</th>\n",
       "      <th>organizations</th>\n",
       "      <th>classifications</th>\n",
       "      <th>affiliations</th>\n",
       "      <th>auth-keywords</th>\n",
       "      <th>reference</th>\n",
       "      <th>subject</th>\n",
       "      <th>grouped_subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>journal of health research</td>\n",
       "      <td>['College of Public Health Sciences', 'Chulalo...</td>\n",
       "      <td>['ASJC', 'SUBJABBR']</td>\n",
       "      <td>['Chulalongkorn University']</td>\n",
       "      <td>['Antibiotic resistance', 'Antibiotics', 'Nepa...</td>\n",
       "      <td>['What is antimicrobial resistance?', 'PLoS On...</td>\n",
       "      <td>health policy</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>journal of health research</td>\n",
       "      <td>['Department of Preventive and Social Medicine...</td>\n",
       "      <td>['ASJC', 'SUBJABBR']</td>\n",
       "      <td>['Duke-NUS Medical School', 'Chulalongkorn Uni...</td>\n",
       "      <td>['Adult', 'Dental caries', 'Elderly', 'System ...</td>\n",
       "      <td>['Department of Health, Ministry of Public Hea...</td>\n",
       "      <td>environmental and occupational health</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journal of health research</td>\n",
       "      <td>['College of Public Health Sciences', 'Chulalo...</td>\n",
       "      <td>['ASJC', 'SUBJABBR']</td>\n",
       "      <td>['Chulalongkorn University']</td>\n",
       "      <td>['Keywords Contraceptive utilization', 'Myanma...</td>\n",
       "      <td>['Pan Afr Med J', 'Iran J Nurs Midwifery Res',...</td>\n",
       "      <td>public health</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>journal of health research</td>\n",
       "      <td>['College of Public Health Sciences', 'Chulalo...</td>\n",
       "      <td>['ASJC', 'SUBJABBR']</td>\n",
       "      <td>['Chulalongkorn University']</td>\n",
       "      <td>['Adolescent health', 'Health belief model', '...</td>\n",
       "      <td>['Sexual and reproductive health of young peop...</td>\n",
       "      <td>health policy</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>journal of health research</td>\n",
       "      <td>['College of Public Health Sciences', 'Chulalo...</td>\n",
       "      <td>['ASJC', 'SUBJABBR']</td>\n",
       "      <td>['Chulalongkorn University']</td>\n",
       "      <td>['Hepatitis C virus', 'Pakistan', 'Pregnant wo...</td>\n",
       "      <td>['Clin Liver Dis', 'Genomic integration of hep...</td>\n",
       "      <td>public health</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 publish_name  \\\n",
       "0  journal of health research   \n",
       "1  journal of health research   \n",
       "2  journal of health research   \n",
       "3  journal of health research   \n",
       "4  journal of health research   \n",
       "\n",
       "                                       organizations       classifications  \\\n",
       "0  ['College of Public Health Sciences', 'Chulalo...  ['ASJC', 'SUBJABBR']   \n",
       "1  ['Department of Preventive and Social Medicine...  ['ASJC', 'SUBJABBR']   \n",
       "2  ['College of Public Health Sciences', 'Chulalo...  ['ASJC', 'SUBJABBR']   \n",
       "3  ['College of Public Health Sciences', 'Chulalo...  ['ASJC', 'SUBJABBR']   \n",
       "4  ['College of Public Health Sciences', 'Chulalo...  ['ASJC', 'SUBJABBR']   \n",
       "\n",
       "                                        affiliations  \\\n",
       "0                       ['Chulalongkorn University']   \n",
       "1  ['Duke-NUS Medical School', 'Chulalongkorn Uni...   \n",
       "2                       ['Chulalongkorn University']   \n",
       "3                       ['Chulalongkorn University']   \n",
       "4                       ['Chulalongkorn University']   \n",
       "\n",
       "                                       auth-keywords  \\\n",
       "0  ['Antibiotic resistance', 'Antibiotics', 'Nepa...   \n",
       "1  ['Adult', 'Dental caries', 'Elderly', 'System ...   \n",
       "2  ['Keywords Contraceptive utilization', 'Myanma...   \n",
       "3  ['Adolescent health', 'Health belief model', '...   \n",
       "4  ['Hepatitis C virus', 'Pakistan', 'Pregnant wo...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  ['What is antimicrobial resistance?', 'PLoS On...   \n",
       "1  ['Department of Health, Ministry of Public Hea...   \n",
       "2  ['Pan Afr Med J', 'Iran J Nurs Midwifery Res',...   \n",
       "3  ['Sexual and reproductive health of young peop...   \n",
       "4  ['Clin Liver Dis', 'Genomic integration of hep...   \n",
       "\n",
       "                                 subject grouped_subject  \n",
       "0                          health policy        Medicine  \n",
       "1  environmental and occupational health        Medicine  \n",
       "2                          public health        Medicine  \n",
       "3                          health policy        Medicine  \n",
       "4                          public health        Medicine  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LDx6g1yyVbGy",
    "outputId": "00314262-0549-4fd1-95dd-3ae264a1c59d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "c7K1kZ316EgF",
    "outputId": "c20496e1-1539-4ef8-fb21-5283ed7384d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>health policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>environmental and occupational health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>public health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> object</label>"
      ],
      "text/plain": [
       "0                            health policy\n",
       "1    environmental and occupational health\n",
       "2                            public health\n",
       "3                            health policy\n",
       "4                            public health\n",
       "Name: subject, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0uPueEeVku7",
    "outputId": "2a49bce7-5730-45b6-c219-f970758685b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['publish_name', 'organizations', 'classifications', 'affiliations',\n",
       "       'auth-keywords', 'reference', 'subject', 'grouped_subject',\n",
       "       'combined_text', 'Book Type Encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "2HTSx9Ng2dCf"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "MRo7eL6zy91X"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Combine text columns\n",
    "df[\"combined_text\"] = df[\"organizations\"] + \" classifications: \" + df[\"classifications\"] + \\\n",
    "                      \" publish_name: \" + df[\"publish_name\"] + \" auth-keywords: \" + df[\"auth-keywords\"]\n",
    "\n",
    "# Clean text\n",
    "def clean_text(text):\n",
    "    # Remove brackets and extra quotes\n",
    "    text = re.sub(r\"[\\[\\]']\", \"\", str(text))\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "df[\"combined_text\"] = df[\"combined_text\"].apply(clean_text)\n",
    "\n",
    "# Normalize text\n",
    "def normalize_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    return text\n",
    "\n",
    "df[\"combined_text\"] = df[\"combined_text\"].apply(normalize_text)\n",
    "\n",
    "# Encode the \"Book Type\" as labels\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Book Type Encoded\"] = label_encoder.fit_transform(df[\"grouped_subject\"])\n",
    "num_classes = len(label_encoder.classes_)  # Total categories\n",
    "\n",
    "# Prepare input (X) and output (y)\n",
    "X = df[\"combined_text\"]\n",
    "y = to_categorical(df[\"Book Type Encoded\"], num_classes=num_classes)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert X_train and X_test to NumPy arrays\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "# Convert text input to numerical format using TextVectorization\n",
    "vectorizer = tf.keras.layers.TextVectorization(max_tokens=1000, output_sequence_length=100)\n",
    "vectorizer.adapt(X_train)  # Adapts to raw text\n",
    "\n",
    "# Vectorize the text\n",
    "X_train_vec = vectorizer(X_train)\n",
    "X_test_vec = vectorizer(X_test)\n",
    "\n",
    "# Convert tensor to NumPy arrays for compatibility (optional, depending on your framework setup)\n",
    "X_train_vec = np.array(X_train_vec)\n",
    "X_test_vec = np.array(X_test_vec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E0rmtvMa2jKC",
    "outputId": "242056aa-f530-4edd-a7db-269e340d8a8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    college of public health sciences chulalongkor...\n",
      "Name: combined_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"combined_text\"].head(1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "aLGDH9My3aRu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3It1--9XVPUX",
    "outputId": "ad9d2b02-fc0b-4f63-a81e-3c8a63d34f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.1478 - loss: 2.6717 - val_accuracy: 0.2156 - val_loss: 2.0166 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1971 - loss: 2.1888 - val_accuracy: 0.2405 - val_loss: 1.9729 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2137 - loss: 2.0922 - val_accuracy: 0.2460 - val_loss: 1.9499 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2166 - loss: 2.0314 - val_accuracy: 0.2468 - val_loss: 1.9334 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2316 - loss: 1.9793 - val_accuracy: 0.2598 - val_loss: 1.9216 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2368 - loss: 1.9652 - val_accuracy: 0.2640 - val_loss: 1.9116 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2445 - loss: 1.9412 - val_accuracy: 0.2640 - val_loss: 1.9024 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2637 - loss: 1.9109 - val_accuracy: 0.2656 - val_loss: 1.8947 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2671 - loss: 1.9014 - val_accuracy: 0.2756 - val_loss: 1.8855 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2525 - loss: 1.9027 - val_accuracy: 0.2747 - val_loss: 1.8792 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2679 - loss: 1.8868 - val_accuracy: 0.2778 - val_loss: 1.8705 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2780 - loss: 1.8738 - val_accuracy: 0.2808 - val_loss: 1.8633 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2796 - loss: 1.8673 - val_accuracy: 0.2847 - val_loss: 1.8562 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2791 - loss: 1.8636 - val_accuracy: 0.2850 - val_loss: 1.8503 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2825 - loss: 1.8560 - val_accuracy: 0.2891 - val_loss: 1.8444 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2934 - loss: 1.8306 - val_accuracy: 0.2924 - val_loss: 1.8369 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2903 - loss: 1.8303 - val_accuracy: 0.2927 - val_loss: 1.8314 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3026 - loss: 1.8219 - val_accuracy: 0.2938 - val_loss: 1.8264 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3125 - loss: 1.8033 - val_accuracy: 0.2935 - val_loss: 1.8204 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3134 - loss: 1.7992 - val_accuracy: 0.2941 - val_loss: 1.8130 - learning_rate: 0.0010\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3016 - loss: 1.8191 - val_accuracy: 0.2894 - val_loss: 1.8194\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2787 - loss: 1.8432\n",
      "Test Accuracy: 0.29\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Predicted Labels: ['Medicine' 'Medicine' 'Engineering' ... 'Social Sciences' 'Medicine'\n",
      " 'Physics and Astronomy']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Build the DNN model\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train_vec.shape[1],)),  # Increase neurons\n",
    "    BatchNormalization(),  # Normalize layer output\n",
    "    Dropout(0.4),  # Prevent overfitting\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')  # Output layer with softmax for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model with Adamax optimizer\n",
    "model.compile(\n",
    "    optimizer='adamax',  # Slight variation of Adam, works well for sparse data\n",
    "    loss='categorical_crossentropy',  # Use categorical crossentropy for multi-class classification\n",
    "    metrics=['accuracy']  # Track accuracy during training\n",
    ")\n",
    "\n",
    "# Early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)  # Stops when no improvement\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5)  # Reduces LR when loss plateaus\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_vec, y_train,\n",
    "    validation_data=(X_test_vec, y_test),\n",
    "    epochs=20,  # Set a higher number of epochs to allow learning rate scheduling to work\n",
    "    batch_size=32,  # Adjust batch size based on your dataset size and memory\n",
    "    callbacks=[early_stopping, reduce_lr]  # Add callbacks to monitor training\n",
    ")\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_vec, y_train, validation_data=(X_test_vec, y_test), epochs=1, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_vec, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test_vec)\n",
    "predicted_labels = label_encoder.inverse_transform(predictions.argmax(axis=1))\n",
    "\n",
    "print(\"Predicted Labels:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pehm1HxCi1ph",
    "outputId": "0bdcf330-8465-4ae0-c192-b5e41dcecd67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- predicted\n",
      "Medicine\n",
      "-------------------------------------\n",
      "Predicted most common class: Medicine with 1670 occurrences\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "class_counts = Counter(predicted_labels)\n",
    "most_common_class, count = class_counts.most_common(1)[0]\n",
    "print(\"-------------------------- predicted\")\n",
    "print(most_common_class)\n",
    "print(\"-------------------------------------\")\n",
    "print(f\"Predicted most common class: {most_common_class} with {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "7TrKF04O7hck"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('my_dnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example function to preprocess input (modify according to your data requirements)\n",
    "def preprocess_input(book_info):\n",
    "    def clean_text(text):  \n",
    "      text = re.sub(r\"[\\[\\]']\", \"\", str(text))\n",
    "      text = re.sub(r\"\\s+\", \" \", text)\n",
    "      return text.strip()\n",
    "\n",
    "    book_info = clean_text(book_info)\n",
    "\n",
    "\n",
    "    def normalize_text(text):\n",
    "        text = text.lower()\n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        return text\n",
    "     \n",
    "    book_info = normalize_text(book_info)\n",
    "    \"\"\"\n",
    "    Preprocess the book information (e.g., title, abstract).\n",
    "    This will depend on how your model was trained.\n",
    "    \"\"\"\n",
    "    # For example, if the input is text, tokenize and pad sequences\n",
    "    # Here, we assume 'tokenizer' is a tokenizer you used during training\n",
    "    \n",
    "    \n",
    "    new_input_vectorized = vectorizer(np.array([book_info]))  # Wrap in np.array to match expected input format\n",
    "\n",
    "    # Convert to numpy array if needed\n",
    "    new_input_vectorized = np.array(new_input_vectorized)\n",
    "    return new_input_vectorized\n",
    "\n",
    "# Function to predict the subject\n",
    "def predict_subject(publich_name,  organizations, classifications,auth_keywords):\n",
    "    feature_string = organizations + \" classifications: \" + classifications + \\\n",
    "                      \" publish_name: \" + publich_name + \" auth-keywords: \" + auth_keywords\n",
    " \n",
    "\n",
    "    # Preprocess the book information\n",
    "    processed_input = preprocess_input(feature_string)\n",
    "    \n",
    "    # Predict the probabilities for each subject\n",
    "    predictions = model.predict(processed_input)\n",
    "    \n",
    "    # Get the index of the highest probability\n",
    "    best_subject_index = np.argmax(predictions)\n",
    "    \n",
    "    # Map index to class name (your subject labels)\n",
    " \n",
    "    predicted_subject = label_encoder.inverse_transform([best_subject_index])[0]\n",
    "    \n",
    "    return predicted_subject\n",
    "\n",
    "# Example usage\n",
    "book_publich_name = \"Introduction to Quantum Physics\"\n",
    "book_organizations = \"College of Public Health Sciences\"\n",
    "book_classifications = \"['ASJC', 'SUBJABBR']\"\n",
    "auth_keywords =  \"['Antibiotic resistance', 'Antibiotics']\"\n",
    "\n",
    "predicted_subject = predict_subject(book_publich_name, book_organizations, book_classifications, auth_keywords)\n",
    "print(f\"Predicted Subject: {predicted_subject}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
